{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## order_create_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "routing_criteria = \"\"\"\n",
    "    이전 대화에서 판매 중인 상품 목록을 제시했는지 확인해.\n",
    "    만약 판매중인 상품 목록을 제시하지 않았다면 fetch_product_list를 출력해.\n",
    "    고객이 주문할 품목을 말했다면 TodOrderRequestConfirmation를 출력해.\n",
    "    고객이 주문을 진행하려는 내용에 동의했다면 create_order를 출력해.\n",
    "    \"\"\"\n",
    "\n",
    "order_create_router_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            너는 주문을 생성하는 유능한 주문봇이야.\n",
    "            적절한 도구를 사용해 고객의 요청을 처리해.\n",
    "            고객이 응답이 필요할 때는 도구를 사용하지 말고 고객에게 응답을 부탁해.\n",
    "            create_order를 사용해 실제로 주문을 생성하기 전에는 주문을 했다는 거짓말을 하면 안돼.\n",
    "\n",
    "            {routing_criteria}\n",
    "\n",
    "            user_id: {user_info},\n",
    "            \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ").partial(routing_criteria=routing_criteria)\n",
    "\n",
    "order_create_router_runnable = order_create_router_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## routing tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class RecordMisCalssification(BaseModel):\n",
    "    \"\"\"Records misclassification of router\"\"\"\n",
    "    input: str = Field(description=\"라우터에 입력된 메시지\")\n",
    "    classification_of_router: str = Field(description=\"라우터의 분류 결과\")\n",
    "    reason_for_misclassification: str = Field(description=\" 라우터의 분류 결과가 잘못된 이유\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "check_routing_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            너는 라우팅 결과가 올바른지 꼼꼼하게 점검해야 해.\n",
    "            라우팅 기준: {routing_criteria}\n",
    "            입력 메시지: {input_message}\n",
    "            모델의 분류 결과: {model_classification}\n",
    "\n",
    "            라우팅 결과가 올바르다면 good을 출력해.\n",
    "            라우팅 결과가 올바르지 않다면 도구를 사용해 문제점을 기록해.            \n",
    "            \n",
    "            \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ").partial(routing_criteria=routing_criteria)\n",
    "\n",
    "model=\"gpt-4o\"\n",
    "gpt4o = ChatOpenAI(model=model)\n",
    "check_routing_runnable = check_routing_prompt | gpt4o.bind_tools([RecordMisCalssification])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_vVNdZmOxpGCm53tMDkRtsdf7', 'function': {'arguments': '{\"input\":\"주문할게요\",\"classification_of_router\":\"fetch_product_list\",\"reason_for_misclassification\":\"고객이 주문을 진행하려는 내용에 동의했습니다. create_order를 출력해야 합니다.\"}', 'name': 'RecordMisCalssification'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 256, 'total_tokens': 313}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_dd932ca5d1', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-079aa041-1f62-40c0-9ddb-6c1cc1421cc6-0', tool_calls=[{'name': 'RecordMisCalssification', 'args': {'input': '주문할게요', 'classification_of_router': 'fetch_product_list', 'reason_for_misclassification': '고객이 주문을 진행하려는 내용에 동의했습니다. create_order를 출력해야 합니다.'}, 'id': 'call_vVNdZmOxpGCm53tMDkRtsdf7'}])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_message = \"주문할게요\"\n",
    "model_classification = \"fetch_product_list\"\n",
    "messages = []\n",
    "\n",
    "output = check_routing_runnable.invoke({\"input_message\": input_message,\n",
    "                                        \"model_classification\": model_classification,\n",
    "                                        \"messages\": messages})\n",
    "output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ttbKuzZoAOQD3G5aqJqQK9Gq', 'function': {'arguments': '{\"input\":\"주문할게요\",\"classification_of_router\":\"TodOrderRequestConfirmation\",\"reason_for_misclassification\":\"The router misclassified the input as TodOrderRequestConfirmation instead of fetch_product_list.\"}', 'name': 'RecordMisCalssification'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 355, 'total_tokens': 410}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4fa71b55-e779-47c6-8f1c-ed51fcd47e6d-0', tool_calls=[{'name': 'RecordMisCalssification', 'args': {'input': '주문할게요', 'classification_of_router': 'TodOrderRequestConfirmation', 'reason_for_misclassification': 'The router misclassified the input as TodOrderRequestConfirmation instead of fetch_product_list.'}, 'id': 'call_ttbKuzZoAOQD3G5aqJqQK9Gq'}])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_message = \"주문할게요\"\n",
    "model_classification = \"TodOrderRequestConfirmation\"\n",
    "messages = []\n",
    "\n",
    "output = check_routing_runnable.invoke({\"input_message\": input_message,\n",
    "                                        \"model_classification\": model_classification,\n",
    "                                        \"messages\": messages})\n",
    "output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '주문할게요',\n",
       " 'classification_of_router': 'TodOrderRequestConfirmation',\n",
       " 'reason_for_misclassification': '라우팅 결과가 올바르지 않음. 주문할게요는 fetch_product_list를 출력해야 함.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3AV4M4oA9jwmWyHqxkLLGX4A', 'function': {'arguments': '{\"input\":\"주문할게요\",\"classification_of_router\":\"TodOrderRequestConfirmation\",\"reason_for_misclassification\":\"라우팅 결과가 올바르지 않음. 주문할게요는 fetch_product_list를 출력해야 함.\"}', 'name': 'RecordMisCalssification'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 300, 'total_tokens': 369}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8b6c2500-a48f-44b8-80af-6b7885f60616-0', tool_calls=[{'name': 'RecordMisCalssification', 'args': {'input': '주문할게요', 'classification_of_router': 'TodOrderRequestConfirmation', 'reason_for_misclassification': '라우팅 결과가 올바르지 않음. 주문할게요는 fetch_product_list를 출력해야 함.'}, 'id': 'call_3AV4M4oA9jwmWyHqxkLLGX4A'}])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "isinstance(output, AIMessage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Optional\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Push or pop the state.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str\n",
    "    dialog_state: Annotated[\n",
    "            list[\n",
    "                Literal[\n",
    "                    \"order_inquiry\",\n",
    "                    \"order_create\",\n",
    "                    \"order_change\",\n",
    "                    \"order_cancel\",\n",
    "                ]\n",
    "            ],\n",
    "            update_dialog_stack,\n",
    "        ]\n",
    "    order_id: int = None \n",
    "    orders: str = None\n",
    "    selected_order: str = None\n",
    "    product_presentation: bool = False\n",
    "    request_order_change_message: bool = False\n",
    "    request_approval_message: bool = False\n",
    "    task_completed: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {\"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        add_state = {k: v for k, v in state.items() if k != \"dialog_state\"}\n",
    "        \n",
    "        return {**add_state, \"messages\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    print(\"-\"*77)\n",
    "    print(\"handle_tool_error 진입\")\n",
    "    print(\"state\\n\", state)\n",
    "    \n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.messages import ToolMessage, AIMessage\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "def order_create_router(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    output = order_create_router_runnable.invoke({\"messages\": messages,\n",
    "                                                  \"user_info\": 1,})\n",
    "\n",
    "    return {\"messages\": output}\n",
    "\n",
    "builder.add_node(\"order_create_router\", order_create_router)\n",
    "        \n",
    "def check_router_result(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "    input_message = messages[-1]\n",
    "    model_classification = messages[-2]\n",
    "\n",
    "    evaluate_classification = order_create_router_runnable.invoke({\"input_message\": input_message,\n",
    "                                                                   \"model_classification\": model_classification,\n",
    "                                                                   \"messages\": messages})\n",
    "    if hasattr(evaluate_classification, \"tool_calls\"):\n",
    "        tool_call_id = evaluate_classification.tool_calls[0][\"id\"]\n",
    "        tool_args = evaluate_classification.tool_calls[0][\"args\"]\n",
    "        tool_output = ToolMessage(\n",
    "                    content=f\"라우터의 분류 결과가 잘못된 것 같습니다. 다음 정보를 활용해 출력을 수정해주세요.{tool_args}\",\n",
    "                    tool_call_id=tool_call_id,\n",
    "                )\n",
    "        return {\"messages\": tool_output}\n",
    "    return state\n",
    "    \n",
    "def after_check_router_result(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    if isinstance(last_message, AIMessage):\n",
    "        return \"order_change\"\n",
    "    else:\n",
    "        return \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "builder.add_node(\"check_router_result\", check_router_result)\n",
    "builder.add_edge(\"order_create_router\", \"check_router_result\")\n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
