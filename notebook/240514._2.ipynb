{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메모리 추가하여 동작 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "message_type_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            너는 고객 입력 메시지를 아래 두 유형 중 하나로 분류하는 로봇이야.\n",
    "            -상품 문의, 주문 내역 조회, 주문 변경 내역 조회, 주문 취소 내역 조회: '문의'\n",
    "            -주문 요청, 주문 변경 요청, 주문 취소 요청: '요청'\n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            너는 고객 입력 메시지를 아래 두 유형 중 하나로 분류하는 로봇이야.\\n            -상품 문의, 주문 내역 조회, 주문 변경 내역 조회, 주문 취소 내역 조회: '문의'\\n            -주문 요청, 주문 변경 요청, 주문 취소 요청: '요청'\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000212C1A8E170>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000212C1A8CA30>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_message_chain = message_type_prompt | model \n",
    "classify_message_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "classify_message_with_memory = RunnableWithMessageHistory(\n",
    "    classify_message_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "classify_message_with_memory_chain = RunnablePassthrough.assign(msg_type=classify_message_with_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 0b234c89-2aa5-4b37-81b1-4b652bd0cf01 not found for run 0af611e4-db35-48ec-b8e4-c9d2621da63c. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"주문 상태가 '주문 완료'인 주문을 알려줘\",\n",
       " 'user_id': 1,\n",
       " 'msg_type': AIMessage(content='문의', response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 138, 'total_tokens': 140}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9f615600-c11f-404b-879a-98d1fce2587f-0')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_message_with_memory_chain.invoke(\n",
    "    {\"input\": \"주문 상태가 '주문 완료'인 주문을 알려줘\", \n",
    "     \"user_id\": 1},\n",
    "    config={\"configurable\": {\"session_id\": \"test_240514-1\"}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inquiry_request_route(info):\n",
    "    print(\"inquiry_request_route 입력 데이터 -> \", info)\n",
    "    if \"문의\" in info[\"msg_type\"].content.lower():\n",
    "        return handle_inquiry_chain\n",
    "    else:\n",
    "        return \"요청 문의 처리 체인 구현 예정\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "classify_inquiry_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            너는 고객의 문의에 대응되는 주문 상태를 판단하는 로봇이야.\n",
    "            사용자가 입력한 메시지를 보고 아래 주문 상태 중 하나로 분류해야 해.\n",
    "            -주문 상품에 관한 문의: '주문 완료'\n",
    "            -주문 변경에 관한 문의: '주문 변경'\n",
    "            -주문 취소에 관한 문의: '주문 취소'\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_inquiry_chain = RunnablePassthrough.assign(inquiry_type=classify_inquiry_prompt | model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completed_orders(dict):\n",
    "    user_id = dict[\"user_id\"]\n",
    "    return f\"사용자 {user_id}의 주문 완료된 주문내역 조회 완료\"\n",
    "\n",
    "def get_payment_completed_orders(dict):\n",
    "    user_id = dict[\"user_id\"]\n",
    "    return f\"사용자 {user_id}의입금 완료된 주문내역 조회 완료\"\n",
    "\n",
    "def get_changed_orders(dict):\n",
    "    user_id = dict[\"user_id\"]\n",
    "    return f\"사용자 {user_id}의주문 변경된 주문내역 조회 완료\"\n",
    "\n",
    "def get_canceled_orders(dict):\n",
    "    user_id = dict[\"user_id\"]\n",
    "    return f\"사용자 {user_id}의주문 취소된 주문내역 조회 완료\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def inquiry_types_route(info):\n",
    "    print(\"inquiry_types_route 함수로 전달된 데이터 -> \", info)\n",
    "    if \"주문 변경\" in info[\"inquiry_type\"].content.lower():\n",
    "        return RunnableLambda(get_changed_orders)\n",
    "    elif \"주문 취소\" in info[\"inquiry_type\"].content.lower():\n",
    "        return RunnableLambda(get_canceled_orders)\n",
    "    else:\n",
    "        return RunnableLambda(get_completed_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "handle_inquiry_chain = classify_inquiry_chain | RunnableLambda(inquiry_types_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  msg_type: RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              chat_history: RunnableBinding(bound=RunnableLambda(_enter_history), config={'run_name': 'load_history'})\n",
       "            }), config={'run_name': 'insert_history'})\n",
       "            | RunnableBinding(bound=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            너는 고객 입력 메시지를 아래 두 유형 중 하나로 분류하는 로봇이야.\\n            -상품 문의, 주문 내역 조회, 주문 변경 내역 조회, 주문 취소 내역 조회: '문의'\\n            -주문 요청, 주문 변경 요청, 주문 취소 요청: '요청'\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "              | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000212C1A8E170>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x00000212C1A8CA30>, openai_api_key=SecretStr('**********'), openai_proxy=''), config_factories=[<function Runnable.with_listeners.<locals>.<lambda> at 0x00000212C1A036D0>]), config={'run_name': 'RunnableWithMessageHistory'}), get_session_history=<function get_session_history at 0x00000212A0ED01F0>, input_messages_key='input', history_messages_key='chat_history', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])\n",
       "})\n",
       "| RunnableLambda(inquiry_request_route)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain = classify_message_with_memory_chain | inquiry_request_route\n",
    "full_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run da5a59d5-1f05-4c11-ae45-53c6df4c3369 not found for run 24f46938-3eed-4e9d-a2c6-9d955b5632b3. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inquiry_request_route 입력 데이터 ->  {'input': '주문 변경 내역을 알고 싶어', 'user_id': 1, 'msg_type': AIMessage(content='문의', response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 129, 'total_tokens': 131}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5fb93a43-ebec-4850-95aa-fb1afc5fe04e-0')}\n",
      "inquiry_types_route 함수로 전달된 데이터 ->  {'input': '주문 변경 내역을 알고 싶어', 'user_id': 1, 'msg_type': AIMessage(content='문의', response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 129, 'total_tokens': 131}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5fb93a43-ebec-4850-95aa-fb1afc5fe04e-0'), 'inquiry_type': AIMessage(content='주문 변경', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 146, 'total_tokens': 149}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6f66b8c7-849a-473c-8d82-6215d7fddddf-0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'사용자 1의주문 변경된 주문내역 조회 완료'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "full_chain.invoke(\n",
    "    {\"input\": \"주문 변경 내역을 알고 싶어\", \n",
    "     \"user_id\": 1},\n",
    "     config={\"configurable\": {\"session_id\": \"test_240514-1\"}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "store[\"test_240514-1\"]\n",
    "del store[\"test_240514-1\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
