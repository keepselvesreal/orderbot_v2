{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memory 공유 확인 위한 dummy chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "dummy_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a robot that classifies customer input messages into specific types. If order_id is provided, you need to output '조회'.\n",
    "            If order_id is not provided, you need to classify the customer input message into one of the following two types:\n",
    "            - 상품 문의, 주문 내역 조회, 주문 변경 내역 조회, 주문 취소 내역 조회: '문의'\n",
    "            - 주문 요청, 주문 변경 요청, 주문 취소 요청: '요청'\n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"input:{input}\\norder_id:{order_id}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_chain = dummy_prompt | model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "dumy_chain_with_memory = RunnableWithMessageHistory(\n",
    "    dummy_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 9fe8ef79-7c3a-4121-988e-6e74f7141827 not found for run 64f9517c-4bac-4f6d-bb94-9b792ccdea52. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 150, 'total_tokens': 153}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a307cb63-35b7-475e-9758-cafdad36f4e6-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = dumy_chain_with_memory.invoke(\n",
    "    {\"input\": \"주문 취소하고 싶어\", \n",
    "    \"order_id\": None},\n",
    "    config={\"configurable\": {\"session_id\": \"test_240516-1\"}}\n",
    "    )\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 6c7f6fe6-4ae3-454a-9708-bf4a34e735dc not found for run a603b1b6-0a79-45b5-bff6-2015abcda523. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 148, 'total_tokens': 151}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-59176f66-ab4a-417f-a2c1-41eb49820035-0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = dumy_chain_with_memory.invoke(\n",
    "    {\"input\": \"주문 변경하고 싶어\", \n",
    "    \"order_id\": None},\n",
    "    config={\"configurable\": {\"session_id\": \"test_240516-1\"}}\n",
    "    )\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## order_id 받는 부분 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='주문 취소하고 싶어'),\n",
       " AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 150, 'total_tokens': 153}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a307cb63-35b7-475e-9758-cafdad36f4e6-0')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = store[\"test_240516-1\"].messages\n",
    "chat_history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='주문 변경하고 싶어'),\n",
       " AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 148, 'total_tokens': 151}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-59176f66-ab4a-417f-a2c1-41eb49820035-0')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = store[\"test_240516-1\"].messages\n",
    "chat_history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            you need to review the conversation from the latest to the oldest and output either '주문 변경' or '주문 취소'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'order_id'], template='input:{input}\\norder_id:{order_id}'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "order_change_cancel_prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a robot that classifies customer input messages into specific types. \n",
    "            you need to review the conversation from the latest to the oldest and output either '주문 변경' or '주문 취소'.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"input:{input}\\norder_id:{order_id}\"),\n",
    "    ]\n",
    ")\n",
    "order_change_cancel_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            you need to review the conversation from the latest to the oldest and output either '주문 변경' or '주문 취소'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'order_id'], template='input:{input}\\norder_id:{order_id}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_change_or_cancel_chain = order_change_cancel_prompt | model\n",
    "classify_change_or_cancel_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['action_type', 'chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            You need to determine whether the user has responded to the AI's request for approval regarding the action specified in action_type.\\n            \\n            To make this determination, the following conditions must be met:\\n            1. There must be an AIMessage that asks for approval for the action specified in action_type, based on the specified order details.\\n            2. The user must have explicitly expressed consent in response to the AIMessage asking for approval of the action specified in action_type.\\n            \\n            Your response must be either 'yes' or 'no'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['action_type', 'input', 'order_id'], template='input:{input}\\norder_id:{order_id}\\naction_type: {action_type}'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "classify_confirmation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a robot that classifies customer input messages into specific types. \n",
    "            You need to determine whether the user has responded to the AI's request for approval regarding the action specified in action_type.\n",
    "            \n",
    "            To make this determination, the following conditions must be met:\n",
    "            1. There must be an AIMessage that asks for approval for the action specified in action_type, based on the specified order details.\n",
    "            2. The user must have explicitly expressed consent in response to the AIMessage asking for approval of the action specified in action_type.\n",
    "            \n",
    "            Your response must be either 'yes' or 'no'.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"input:{input}\\norder_id:{order_id}\\naction_type: {action_type}\"),\n",
    "    ]\n",
    ")\n",
    "classify_confirmation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['action_type', 'chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            You need to determine whether the user has responded to the AI's request for approval regarding the action specified in action_type.\\n            \\n            To make this determination, the following conditions must be met:\\n            1. There must be an AIMessage that asks for approval for the action specified in action_type, based on the specified order details.\\n            2. The user must have explicitly expressed consent in response to the AIMessage asking for approval of the action specified in action_type.\\n            \\n            Your response must be either 'yes' or 'no'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['action_type', 'input', 'order_id'], template='input:{input}\\norder_id:{order_id}\\naction_type: {action_type}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_confirmation_chain = classify_confirmation_prompt | model \n",
    "classify_confirmation_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(dict):\n",
    "    inputs = dict[\"inputs\"]\n",
    "    action_type =  dict[\"action_type\"]\n",
    "    # action_type = action_type.content\n",
    "    inputs[\"action_type\"] = action_type\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  inputs: RunnablePassthrough(),\n",
       "  action_type: ChatPromptTemplate(input_variables=['chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            you need to review the conversation from the latest to the oldest and output either '주문 변경' or '주문 취소'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'order_id'], template='input:{input}\\norder_id:{order_id}'))])\n",
       "               | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "}\n",
       "| RunnableLambda(helper)\n",
       "| RunnableAssign(mapper={\n",
       "    execution_confirmation: ChatPromptTemplate(input_variables=['action_type', 'chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            You need to determine whether the user has responded to the AI's request for approval regarding the action specified in action_type.\\n            \\n            To make this determination, the following conditions must be met:\\n            1. There must be an AIMessage that asks for approval for the action specified in action_type, based on the specified order details.\\n            2. The user must have explicitly expressed consent in response to the AIMessage asking for approval of the action specified in action_type.\\n            \\n            Your response must be either 'yes' or 'no'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['action_type', 'input', 'order_id'], template='input:{input}\\norder_id:{order_id}\\naction_type: {action_type}'))])\n",
       "                            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "  })"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "exp_chain = (\n",
    "    {\n",
    "        \"inputs\": RunnablePassthrough(),\n",
    "        \"action_type\": classify_change_or_cancel_chain\n",
    "    } | RunnableLambda(helper) | RunnablePassthrough.assign(execution_confirmation=classify_confirmation_chain)\n",
    "    )\n",
    "exp_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='주문 취소하고 싶어'),\n",
       "  AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 150, 'total_tokens': 153}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a307cb63-35b7-475e-9758-cafdad36f4e6-0')],\n",
       " 'input': None,\n",
       " 'order_id': 7,\n",
       " 'action_type': AIMessage(content='주문 취소', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 87, 'total_tokens': 92}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8f8e0b68-dd37-4260-8f06-0476ee3095de-0'),\n",
       " 'execution_confirmation': AIMessage(content='no', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 273, 'total_tokens': 274}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3a3b487d-d358-4f9b-b3c4-95cc932dcf86-0')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = exp_chain.invoke(\n",
    "    {\"chat_history\": chat_history,\n",
    "     \"input\": None,\n",
    "     \"order_id\": 7}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 요청 승인 여부에 따른 라우트\n",
    "* 승인O -> 처리 진행\n",
    "* 승인X -> 메시지 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_recent_orders(dict):\n",
    "    print(dict)\n",
    "    return \"produdct: 백설기 quantity: 2 price: 13,000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "근데, fetch_recent_orders은 execution_confirmation이 no인 경우에만 실행되기에 exp_chain이 아니라 generate_confirm_message_chain과 결합해야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  inputs: RunnablePassthrough(),\n",
       "  action_type: ChatPromptTemplate(input_variables=['chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            you need to review the conversation from the latest to the oldest and output either '주문 변경' or '주문 취소'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'order_id'], template='input:{input}\\norder_id:{order_id}'))])\n",
       "               | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "}\n",
       "| RunnableLambda(helper)\n",
       "| RunnableAssign(mapper={\n",
       "    execution_confirmation: ChatPromptTemplate(input_variables=['action_type', 'chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            You need to determine whether the user has responded to the AI's request for approval regarding the action specified in action_type.\\n            \\n            To make this determination, the following conditions must be met:\\n            1. There must be an AIMessage that asks for approval for the action specified in action_type, based on the specified order details.\\n            2. The user must have explicitly expressed consent in response to the AIMessage asking for approval of the action specified in action_type.\\n            \\n            Your response must be either 'yes' or 'no'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['action_type', 'input', 'order_id'], template='input:{input}\\norder_id:{order_id}\\naction_type: {action_type}'))])\n",
       "                            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "  })\n",
       "| RunnableAssign(mapper={\n",
       "    queried_result: RunnableLambda(fetch_recent_orders)\n",
       "  })"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_chain2 = exp_chain | RunnablePassthrough.assign(queried_result=fetch_recent_orders)\n",
    "exp_chain2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': [HumanMessage(content='주문 취소하고 싶어'), AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 150, 'total_tokens': 153}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a307cb63-35b7-475e-9758-cafdad36f4e6-0')], 'input': None, 'order_id': 7, 'action_type': AIMessage(content='주문 취소', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 87, 'total_tokens': 92}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4983409c-6a0f-4d52-be4e-eb339b2d6c6f-0'), 'execution_confirmation': AIMessage(content='no', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 276, 'total_tokens': 277}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6d5090aa-0661-4911-a306-06134225f3c4-0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='주문 취소하고 싶어'),\n",
       "  AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 150, 'total_tokens': 153}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a307cb63-35b7-475e-9758-cafdad36f4e6-0')],\n",
       " 'input': None,\n",
       " 'order_id': 7,\n",
       " 'action_type': AIMessage(content='주문 취소', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 87, 'total_tokens': 92}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4983409c-6a0f-4d52-be4e-eb339b2d6c6f-0'),\n",
       " 'execution_confirmation': AIMessage(content='no', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 276, 'total_tokens': 277}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6d5090aa-0661-4911-a306-06134225f3c4-0'),\n",
       " 'queried_result': 'produdct: 백설기 quantity: 2 price: 13,000'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = exp_chain2.invoke(\n",
    "    {\"chat_history\": chat_history,\n",
    "     \"input\": None,\n",
    "     \"order_id\": 7}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 승인 메시지 작성 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "generate_confirm_message_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a robot that generates a confirmation request message based on the action_type and queried_result.\n",
    "            create a message to show the queried_result and ask for final confirmation considering action_type.\n",
    "            The response should be generated in Korean.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        # MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"action_type:{action_type}\\nqueried_result:{queried_result}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['action_type', 'queried_result'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='\\n            You are a robot that generates a confirmation request message based on the action_type and queried_result.\\n            create a message to show the queried_result and ask for final confirmation considering action_type.\\n            The response should be generated in Korean.\\n            ')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['action_type', 'queried_result'], template='action_type:{action_type}\\nqueried_result:{queried_result}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_confirm_message_chain = generate_confirm_message_prompt | model\n",
    "generate_confirm_message_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution_or_message_route(info):\n",
    "    print(\"execution_or_message_route 함수로 전달된 데이터 -> \", info)\n",
    "    if \"yes\" in info[\"execution_confirmation\"].content.lower():\n",
    "        return \"주문 변경 또는 취소 진행\"\n",
    "    else:\n",
    "        return RunnablePassthrough.assign(queried_result=fetch_recent_orders) | generate_confirm_message_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  inputs: RunnablePassthrough(),\n",
       "  action_type: ChatPromptTemplate(input_variables=['chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            you need to review the conversation from the latest to the oldest and output either '주문 변경' or '주문 취소'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'order_id'], template='input:{input}\\norder_id:{order_id}'))])\n",
       "               | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "}\n",
       "| RunnableLambda(helper)\n",
       "| RunnableAssign(mapper={\n",
       "    execution_confirmation: ChatPromptTemplate(input_variables=['action_type', 'chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            You need to determine whether the user has responded to the AI's request for approval regarding the action specified in action_type.\\n            \\n            To make this determination, the following conditions must be met:\\n            1. There must be an AIMessage that asks for approval for the action specified in action_type, based on the specified order details.\\n            2. The user must have explicitly expressed consent in response to the AIMessage asking for approval of the action specified in action_type.\\n            \\n            Your response must be either 'yes' or 'no'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['action_type', 'input', 'order_id'], template='input:{input}\\norder_id:{order_id}\\naction_type: {action_type}'))])\n",
       "                            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "  })\n",
       "| RunnableLambda(execution_route)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution_chain = exp_chain | execution_or_message_route\n",
    "execution_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 메시지가 chat_history에 저장돼야 하는데 지금 Runnable 뭐시기에선 이게 내 생각대로 잘 구현되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution_route 함수로 전달된 데이터 ->  {'chat_history': [HumanMessage(content='주문 취소하고 싶어'), AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 150, 'total_tokens': 153}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a307cb63-35b7-475e-9758-cafdad36f4e6-0')], 'input': None, 'order_id': 7, 'action_type': AIMessage(content='주문 취소', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 87, 'total_tokens': 92}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-440ccfb9-1ca8-44fc-a714-0b7170496e31-0'), 'execution_confirmation': AIMessage(content='no', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 271, 'total_tokens': 272}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4602ba6b-dd1b-48a0-9609-5e95422d1a4d-0')}\n",
      "{'chat_history': [HumanMessage(content='주문 취소하고 싶어'), AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 150, 'total_tokens': 153}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a307cb63-35b7-475e-9758-cafdad36f4e6-0')], 'input': None, 'order_id': 7, 'action_type': AIMessage(content='주문 취소', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 87, 'total_tokens': 92}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-440ccfb9-1ca8-44fc-a714-0b7170496e31-0'), 'execution_confirmation': AIMessage(content='no', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 271, 'total_tokens': 272}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4602ba6b-dd1b-48a0-9609-5e95422d1a4d-0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='주문 내역 확인 요청:  \\n상품: 백설기  \\n수량: 2개  \\n가격: 13,000원  \\n\\n위 주문 내역을 확인하고 주문을 취소하시겠습니까?', response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 185, 'total_tokens': 250}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4f96778b-558f-4377-ab82-5765bc1c4490-0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = execution_chain.invoke(\n",
    "    {\"chat_history\": chat_history,\n",
    "     \"input\": None,\n",
    "     \"order_id\": 7}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_confirm_message_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a robot that generates a confirmation request message based on the action_type and queried_result.\n",
    "            Create a message to show the queried_result and ask for final confirmation considering action_type.\n",
    "            If action_type is '주문 변경', instead of asking for final confirmation, include a request for the user to specify how they want to change the order if the queried order is correct.\n",
    "            The response should be generated in Korean.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        # MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"action_type:{action_type}\\nqueried_result:{queried_result}\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['action_type', 'queried_result'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that generates a confirmation request message based on the action_type and queried_result.\\n            Create a message to show the queried_result and ask for final confirmation considering action_type.\\n            If action_type is '주문 변경', instead of asking for final confirmation, include a request for the user to specify how they want to change the order if the queried order is correct.\\n            The response should be generated in Korean.\\n            \")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['action_type', 'queried_result'], template='action_type:{action_type}\\nqueried_result:{queried_result}'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_confirm_message_chain = generate_confirm_message_prompt | model\n",
    "generate_confirm_message_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  inputs: RunnablePassthrough(),\n",
       "  action_type: ChatPromptTemplate(input_variables=['chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            you need to review the conversation from the latest to the oldest and output either '주문 변경' or '주문 취소'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'order_id'], template='input:{input}\\norder_id:{order_id}'))])\n",
       "               | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "}\n",
       "| RunnableLambda(helper)\n",
       "| RunnableAssign(mapper={\n",
       "    execution_confirmation: ChatPromptTemplate(input_variables=['action_type', 'chat_history', 'input', 'order_id'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"\\n            You are a robot that classifies customer input messages into specific types. \\n            You need to determine whether the user has responded to the AI's request for approval regarding the action specified in action_type.\\n            \\n            To make this determination, the following conditions must be met:\\n            1. There must be an AIMessage that asks for approval for the action specified in action_type, based on the specified order details.\\n            2. The user must have explicitly expressed consent in response to the AIMessage asking for approval of the action specified in action_type.\\n            \\n            Your response must be either 'yes' or 'no'.\\n            \")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['action_type', 'input', 'order_id'], template='input:{input}\\norder_id:{order_id}\\naction_type: {action_type}'))])\n",
       "                            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001F54878D660>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F54878F250>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "  })\n",
       "| RunnableLambda(execution_or_message_route)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution_chain = exp_chain | execution_or_message_route\n",
    "execution_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution_or_message_route 함수로 전달된 데이터 ->  {'chat_history': [HumanMessage(content='주문 변경하고 싶어'), AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 148, 'total_tokens': 151}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-59176f66-ab4a-417f-a2c1-41eb49820035-0')], 'input': None, 'order_id': 7, 'action_type': AIMessage(content='주문 변경', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 85, 'total_tokens': 88}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-30afe04b-a88f-47c3-8f5f-9db544adf1c2-0'), 'execution_confirmation': AIMessage(content='no', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 270, 'total_tokens': 271}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9d50b9a7-6cce-4276-a7d9-fda8ffe81302-0')}\n",
      "{'chat_history': [HumanMessage(content='주문 변경하고 싶어'), AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 148, 'total_tokens': 151}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-59176f66-ab4a-417f-a2c1-41eb49820035-0')], 'input': None, 'order_id': 7, 'action_type': AIMessage(content='주문 변경', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 85, 'total_tokens': 88}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-30afe04b-a88f-47c3-8f5f-9db544adf1c2-0'), 'execution_confirmation': AIMessage(content='no', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 270, 'total_tokens': 271}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9d50b9a7-6cce-4276-a7d9-fda8ffe81302-0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='주문 내역을 확인해주세요:\\n상품: 백설기\\n수량: 2개\\n가격: 13,000원\\n\\n주문을 변경하시려면 변경 사항을 알려주세요. 변경하지 않으시려면 확인해 주세요.', response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 225, 'total_tokens': 297}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-76ef5c81-0069-4f34-be10-ceb67c76b88a-0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = execution_chain.invoke(\n",
    "    {\"chat_history\": chat_history,\n",
    "     \"input\": None,\n",
    "     \"order_id\": 7}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 승인 확인 후 작업 진행 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancel_order(dict):\n",
    "    order_id = dict[\"order_id\"]\n",
    "    return f\"주문{order_id} 취소\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution_route(info):\n",
    "    print(\"execution_route 함수로 전달된 데이터 -> \", info)\n",
    "    if \"주문 변경\" in info[\"action_type\"].content:\n",
    "        return \n",
    "    else:\n",
    "        return cancel_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancel_order(data: dict) -> dict:\n",
    "    order_id = data[\"order_id\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
