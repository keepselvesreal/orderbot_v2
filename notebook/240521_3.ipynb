{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    save_mode: Optional[str] = Field(default=\"both\")  # \"input\", \"output\", \"both\"\n",
    "    \n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        \"\"\"조건에 따라 메시지를 저장\"\"\"\n",
    "        if self.save_mode == \"input\":\n",
    "            input_messages = [msg for msg in messages if isinstance(msg, HumanMessage)]\n",
    "            self.messages.extend(input_messages)\n",
    "        elif self.save_mode == \"output\":\n",
    "            output_messages = [msg for msg in messages if isinstance(msg, AIMessage)]\n",
    "            self.messages.extend(output_messages)\n",
    "        elif self.save_mode == \"both\":\n",
    "            self.messages.extend(messages)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_by_session_id(session_id: str, save_mode: str = \"both\") -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory(save_mode=save_mode)\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "class RunnableWithMessageHistory(Runnable):\n",
    "    def __init__(self, runnable: Runnable, get_session_history, input_messages_key: str, history_messages_key: str, context_key: Optional[str] = None):\n",
    "        self.runnable = runnable\n",
    "        self.get_session_history = get_session_history\n",
    "        self.input_messages_key = input_messages_key\n",
    "        self.history_messages_key = history_messages_key\n",
    "        self.context_key = context_key\n",
    "    \n",
    "    def invoke(self, input: Dict[str, Any], config: Optional[Dict[str, Any]] = None) -> Any:\n",
    "        session_id = config[\"configurable\"][\"session_id\"]\n",
    "        history = self.get_session_history(session_id)\n",
    "        \n",
    "        current_input = input[self.input_messages_key]\n",
    "        \n",
    "        if isinstance(current_input, str):\n",
    "            current_input_message = HumanMessage(content=current_input)\n",
    "            history.add_messages([current_input_message])\n",
    "        \n",
    "        input[self.history_messages_key] = history.messages\n",
    "        \n",
    "        result = self.runnable.invoke(input, config)\n",
    "        \n",
    "        if isinstance(result, AIMessage):\n",
    "            if self.context_key and self.context_key in input:\n",
    "                context = input[self.context_key]\n",
    "                result_with_context = AIMessage(content=f\"{context}\\n{result.content}\")\n",
    "                history.add_messages([result_with_context])\n",
    "            else:\n",
    "                history.add_messages([result])\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "message_type_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a robot that classifies customer input messages into one of the following two types:\n",
    "            - Product inquiry, order history inquiry, order change history inquiry, order cancellation history inquiry: '문의'\n",
    "            - Order request, order change request, order cancellation request: '요청'\n",
    "            \n",
    "            You need to review the messages in the Messages Placeholder from the latest to the oldest.\n",
    "\n",
    "            Consider the previous AI responses and their classifications to understand the intent behind the current input. \n",
    "            Use this context to make an accurate classification. \n",
    "            If the latest AI response was classified as '요청', and the current input is related to an order, it is likely a '요청'.\n",
    "            \n",
    "            Additionally, if the input contains order details, it should be classified as '요청'.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_message_chain = message_type_prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_message_chain_with_history = RunnableWithMessageHistory(\n",
    "    classify_message_chain,\n",
    "    get_by_session_id,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    context_key=\"context\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='요청' response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 192, 'total_tokens': 195}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-4303dd41-6575-4098-92b1-8ccd0457f585-0'\n"
     ]
    }
   ],
   "source": [
    "result = classify_message_chain_with_history.invoke(\n",
    "    {\"input\": \"주문 변경할게요\", \"context\": \"사용자 입력에 대한 분류\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session_1\"}}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='주문 변경할게요'), AIMessage(content='사용자 입력에 대한 분류\\n요청')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"session_1\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='사용자 입력에 대한 분류\\n문의' response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 240, 'total_tokens': 253}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-42570256-7f8a-440d-a095-944895ef10d5-0'\n"
     ]
    }
   ],
   "source": [
    "result = classify_message_chain_with_history.invoke(\n",
    "    {\"input\": \"판매 상품 좀 알려줘\", \"context\": \"사용자 입력에 대한 분류\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session_1\"}}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "context로 입력한 내용(사용자 입력에 대한 분류)이 중복되어 두 번 입력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='주문 변경할게요'),\n",
       " AIMessage(content='사용자 입력에 대한 분류\\n요청'),\n",
       " HumanMessage(content='판매 상품 좀 알려줘'),\n",
       " AIMessage(content='사용자 입력에 대한 분류\\n사용자 입력에 대한 분류\\n문의')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"session_1\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='사용자 입력에 대한 분류\\n문의' response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 276, 'total_tokens': 289}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-7c1babe8-b8b2-4912-a84b-1355465ee7b4-0'\n"
     ]
    }
   ],
   "source": [
    "result = classify_message_chain_with_history.invoke(\n",
    "    {\"input\": \"주문 취소 가능한가요?\", \"context\": \"사용자 입력에 대한 분류\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session_1\"}}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='주문 변경할게요'),\n",
       " AIMessage(content='사용자 입력에 대한 분류\\n요청'),\n",
       " HumanMessage(content='판매 상품 좀 알려줘'),\n",
       " AIMessage(content='사용자 입력에 대한 분류\\n사용자 입력에 대한 분류\\n문의'),\n",
       " HumanMessage(content='주문 취소 가능한가요?'),\n",
       " AIMessage(content='사용자 입력에 대한 분류\\n사용자 입력에 대한 분류\\n문의')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"session_1\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='사용자 입력에 대한 분류\\n문의' response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 314, 'total_tokens': 327}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-82532bc9-3221-461c-9c26-caa0bf95006b-0'\n"
     ]
    }
   ],
   "source": [
    "result = classify_message_chain_with_history.invoke(\n",
    "    {\"input\": \"주문 변경 가능한가요?\", \"context\": \"\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session_1\"}}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='주문 변경할게요'),\n",
       " AIMessage(content='사용자 입력에 대한 분류\\n요청'),\n",
       " HumanMessage(content='판매 상품 좀 알려줘'),\n",
       " AIMessage(content='사용자 입력에 대한 분류\\n사용자 입력에 대한 분류\\n문의'),\n",
       " HumanMessage(content='주문 취소 가능한가요?'),\n",
       " AIMessage(content='사용자 입력에 대한 분류\\n사용자 입력에 대한 분류\\n문의'),\n",
       " HumanMessage(content='주문 변경 가능한가요?'),\n",
       " AIMessage(content='\\n사용자 입력에 대한 분류\\n문의')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"session_1\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='사용자 입력에 대한 분류\\n요청' response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 346, 'total_tokens': 360}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-1cf5526f-2811-43e6-8c92-b19bcdfe276d-0'\n"
     ]
    }
   ],
   "source": [
    "result = classify_message_chain_with_history.invoke(\n",
    "    {\"input\": \"주문 변경 쌉가능??\", \"context\": \"\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session_1\"}}\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜 콘텍스트 공백 문자 넣어도 이전과 맥락 추가하는 거지? 이전 대화 보고 패턴 파악해서 자동생성하는 건가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='주문 변경할게요'),\n",
       " AIMessage(content='사용자 입력에 대한 분류\\n요청'),\n",
       " HumanMessage(content='판매 상품 좀 알려줘'),\n",
       " AIMessage(content='사용자 입력에 대한 분류\\n사용자 입력에 대한 분류\\n문의'),\n",
       " HumanMessage(content='주문 취소 가능한가요?'),\n",
       " AIMessage(content='사용자 입력에 대한 분류\\n사용자 입력에 대한 분류\\n문의'),\n",
       " HumanMessage(content='주문 변경 가능한가요?'),\n",
       " AIMessage(content='\\n사용자 입력에 대한 분류\\n문의'),\n",
       " HumanMessage(content='주문 변경 쌉가능??'),\n",
       " AIMessage(content='\\n사용자 입력에 대한 분류\\n요청')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"session_1\"].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# helper 코드 동작 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import Runnable, RunnableLambda, RunnablePassthrough\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    save_mode: Optional[str] = Field(default=\"both\")  # \"input\", \"output\", \"both\"\n",
    "    \n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        \"\"\"조건에 따라 메시지를 저장\"\"\"\n",
    "        if self.save_mode == \"input\":\n",
    "            input_messages = [msg for msg in messages if isinstance(msg, HumanMessage)]\n",
    "            self.messages.extend(input_messages)\n",
    "        elif self.save_mode == \"output\":\n",
    "            output_messages = [msg for msg in messages if isinstance(msg, AIMessage)]\n",
    "            self.messages.extend(output_messages)\n",
    "        elif self.save_mode == \"both\":\n",
    "            self.messages.extend(messages)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id: str, save_mode: str = \"both\") -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory(save_mode=save_mode)\n",
    "    return store[session_id]\n",
    "\n",
    "class RunnableWithMessageHistory(Runnable):\n",
    "    def __init__(self, runnable: Runnable, get_session_history, input_messages_key: str, history_messages_key: str, context_key: Optional[str] = None):\n",
    "        self.runnable = runnable\n",
    "        self.get_session_history = get_session_history\n",
    "        self.input_messages_key = input_messages_key\n",
    "        self.history_messages_key = history_messages_key\n",
    "        self.context_key = context_key\n",
    "    \n",
    "    def invoke(self, input: Dict[str, Any], config: Optional[Dict[str, Any]] = None) -> Any:\n",
    "        session_id = config[\"configurable\"][\"session_id\"]\n",
    "        history = self.get_session_history(session_id)\n",
    "        \n",
    "        current_input = input[self.input_messages_key]\n",
    "        \n",
    "        if isinstance(current_input, str):\n",
    "            current_input_message = HumanMessage(content=current_input)\n",
    "            # history.add_messages([current_input_message])\n",
    "        \n",
    "        input[self.history_messages_key] = history.messages\n",
    "        \n",
    "        result = self.runnable.invoke(input, config)\n",
    "        \n",
    "        if isinstance(result, AIMessage):\n",
    "            if self.context_key and self.context_key in input:\n",
    "                context = input[self.context_key]\n",
    "                result_with_context = AIMessage(content=f\"{context}\\n{result.content}\")\n",
    "                history.add_messages([result_with_context])\n",
    "            else:\n",
    "                history.add_messages([result])\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_memory(runnable, session_id, context=\"\", save_mode=\"both\"):\n",
    "    runnable_with_memory = RunnableWithMessageHistory(\n",
    "        runnable,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "        context_key=\"context\"\n",
    "    )\n",
    "    \n",
    "    memory_by_session = RunnableLambda(\n",
    "        lambda input: runnable_with_memory.invoke(\n",
    "            {**input, \"context\": context},\n",
    "            config={\"configurable\": {\"session_id\": session_id,\n",
    "                                     \"save_mode\": save_mode}}\n",
    "        )\n",
    "    )\n",
    "    return memory_by_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION_ID = \"working-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "message_type_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a robot that classifies customer input messages into one of the following two types:\n",
    "            - Product inquiry, order history inquiry, order change history inquiry, order cancellation history inquiry: '문의'\n",
    "            - Order request, order change request, order cancellation request: '요청'\n",
    "            \n",
    "            You need to review the messages in the Messages Placeholder from the latest to the oldest.\n",
    "\n",
    "            Consider the previous AI responses and their classifications to understand the intent behind the current input. \n",
    "            Use this context to make an accurate classification. \n",
    "            If the latest AI response was classified as '요청', and the current input is related to an order, it is likely a '요청'.\n",
    "            \n",
    "            Additionally, if the input contains order details, it should be classified as '요청'.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableLambda(lambda input: runnable_with_memory.invoke({**input, 'context': context}, config={'configurable': {'session_id': session_id, 'save_mode': save_mode}}))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_message_chain = message_type_prompt | model\n",
    "\n",
    "classify_message_with_memory = add_memory(classify_message_chain, SESSION_ID, context=\"사용자 입력 유형 분류\", save_mode=\"both\")\n",
    "classify_message_with_memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='문의', response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 205, 'total_tokens': 207}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-12741c21-4f39-449a-9c3e-d4afbba02594-0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_message_with_memory.invoke({\"input\": \"물건 반품 가능??\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='사용자 입력 유형 분류\\n문의'), AIMessage(content='사용자 입력 유형 분류\\n문의')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"working-test\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classify_message_with_memory_chain = RunnablePassthrough.assign(msg_type=classify_message_with_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '주문 변경하려면 어케 하죠?',\n",
       " 'msg_type': AIMessage(content='사용자 입력 유형\\n요청', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 301, 'total_tokens': 313}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f409ef6f-2157-4f6e-9ed3-81aaf1e9d47c-0')}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = classify_message_with_memory_chain.invoke(\n",
    "    {\"input\": \"주문 변경하려면 어케 하죠?\"}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='주문 취소하려면 어케 하죠?'),\n",
       " AIMessage(content='사용자 입력 유형\\n요청'),\n",
       " HumanMessage(content='주문 취소하려면 어케 하죠?'),\n",
       " AIMessage(content='사용자 입력 유형\\n사용자 입력 유형\\n요청'),\n",
       " HumanMessage(content='주문 변경하려면 어케 하죠?'),\n",
       " AIMessage(content='사용자 입력 유형\\n사용자 입력 유형\\n요청')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"working-test\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
