{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import Runnable, RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "    save_mode: Optional[str] = Field(default=\"both\")  # \"input\", \"output\", \"both\"\n",
    "    \n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        \"\"\"조건에 따라 메시지를 저장\"\"\"\n",
    "        if self.save_mode == \"input\":\n",
    "            input_messages = [msg for msg in messages if isinstance(msg, HumanMessage)]\n",
    "            self.messages.extend(input_messages)\n",
    "        elif self.save_mode == \"output\":\n",
    "            output_messages = [msg for msg in messages if isinstance(msg, AIMessage)]\n",
    "            self.messages.extend(output_messages)\n",
    "        elif self.save_mode == \"both\":\n",
    "            self.messages.extend(messages)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "def get_session_history(session_id: str, save_mode: str = \"both\") -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory(save_mode=save_mode)\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunnableWithMessageHistory(Runnable):\n",
    "    def __init__(self, runnable: Runnable, get_session_history, input_messages_key: str, history_messages_key: str, context_key: Optional[str] = None):\n",
    "        self.runnable = runnable\n",
    "        self.get_session_history = get_session_history\n",
    "        self.input_messages_key = input_messages_key\n",
    "        self.history_messages_key = history_messages_key\n",
    "        self.context_key = context_key\n",
    "    \n",
    "    def invoke(self, input: Dict[str, Any], config: Optional[Dict[str, Any]] = None) -> Any:\n",
    "        session_id = config[\"configurable\"][\"session_id\"]\n",
    "        save_mode = config[\"configurable\"].get(\"save_mode\", \"both\")\n",
    "        history = self.get_session_history(session_id, save_mode)\n",
    "        \n",
    "        current_input = input[self.input_messages_key]\n",
    "        \n",
    "        if isinstance(current_input, str):\n",
    "            current_input_message = HumanMessage(content=current_input)\n",
    "        \n",
    "        input[self.history_messages_key] = history.messages\n",
    "        \n",
    "        result = self.runnable.invoke(input, config)\n",
    "        \n",
    "        if self.context_key and input.get(self.context_key):\n",
    "            context = input[self.context_key]\n",
    "            result_with_context = AIMessage(content=f\"{context}\\n{result.content}\")\n",
    "            history.add_messages([current_input_message, result_with_context])\n",
    "        else:\n",
    "            history.add_messages([current_input_message, result])\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_memory(runnable, session_id, context=\"\", save_mode=\"both\"):\n",
    "    runnable_with_memory = RunnableWithMessageHistory(\n",
    "        runnable,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "        context_key=\"context\"\n",
    "    )\n",
    "    \n",
    "    memory_by_session = RunnableLambda(\n",
    "        lambda input: runnable_with_memory.invoke(\n",
    "            {**input, \"context\": context},\n",
    "            config={\"configurable\": {\"session_id\": session_id,\n",
    "                                     \"save_mode\": save_mode}}\n",
    "        )\n",
    "    )\n",
    "    return memory_by_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_type_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are a robot that classifies customer input messages into one of the following two types:\n",
    "            - Product inquiry, order history inquiry, order change history inquiry, order cancellation history inquiry: '문의'\n",
    "            - Order request, order change request, order cancellation request: '요청'\n",
    "            \n",
    "            You need to review the messages in the Messages Placeholder from the latest to the oldest.\n",
    "\n",
    "            Consider the previous AI responses and their classifications to understand the intent behind the current input. \n",
    "            Use this context to make an accurate classification. \n",
    "            If the latest AI response was classified as '요청', and the current input is related to an order, it is likely a '요청'.\n",
    "            \n",
    "            Additionally, if the input contains order details, it should be classified as '요청'.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "classify_message_chain = message_type_prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='요청' response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 202, 'total_tokens': 205}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-4af717de-1e1c-4b1a-afa1-25e126824a67-0'\n",
      "[HumanMessage(content='주문 취소할게'), AIMessage(content='\\n요청'), HumanMessage(content='주문 취소할게'), AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 202, 'total_tokens': 205}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4af717de-1e1c-4b1a-afa1-25e126824a67-0')]\n"
     ]
    }
   ],
   "source": [
    "runnable_with_memory = add_memory(classify_message_chain, session_id=\"test1\", save_mode=\"both\")\n",
    "print(runnable_with_memory.invoke({\"input\": \"주문 취소할게\"}, config={\"configurable\": {\"session_id\": \"test1\"}}))\n",
    "print(store[\"test1\"].messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='요청' response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 220, 'total_tokens': 223}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-5afcd8d0-0eaf-4946-bc6c-17aeda7b378b-0'\n",
      "[HumanMessage(content='주문 취소할게'), AIMessage(content='\\n요청'), HumanMessage(content='주문 취소할게'), AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 202, 'total_tokens': 205}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4af717de-1e1c-4b1a-afa1-25e126824a67-0'), HumanMessage(content='주문 변경도 가능해?'), AIMessage(content='사용자 입력 유형\\n요청')]\n"
     ]
    }
   ],
   "source": [
    "runnable_with_memory = add_memory(classify_message_chain, session_id=\"test1\", context=\"사용자 입력 유형\", save_mode=\"both\")\n",
    "print(runnable_with_memory.invoke({\"input\": \"주문 변경도 가능해?\"}, config={\"configurable\": {\"session_id\": \"test1\"}}))\n",
    "print(store[\"test1\"].messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='요청' response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 182, 'total_tokens': 185}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-c9251373-fcf5-4198-9664-cc914dbd3db3-0'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'output_only'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m runnable_with_memory \u001b[38;5;241m=\u001b[39m add_memory(classify_message_chain, session_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest1\u001b[39m\u001b[38;5;124m\"\u001b[39m, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m사용자 입력 유형\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(runnable_with_memory\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m주문 변경할게요\u001b[39m\u001b[38;5;124m\"\u001b[39m}, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_only\u001b[39m\u001b[38;5;124m\"\u001b[39m}}))\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_only\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmessages)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'output_only'"
     ]
    }
   ],
   "source": [
    "runnable_with_memory = add_memory(classify_message_chain, session_id=\"test1\", context=\"사용자 입력 유형\", save_mode=\"output\")\n",
    "print(runnable_with_memory.invoke({\"input\": \"주문 변경할게요\"}, config={\"configurable\": {\"session_id\": \"output_only\"}}))\n",
    "print(store[\"output_only\"].messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='요청' response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 182, 'total_tokens': 185}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-913753c5-4a53-4f85-b773-c9348b4ce5e6-0'\n",
      "[AIMessage(content='사용자 입력 유형\\n요청')]\n"
     ]
    }
   ],
   "source": [
    "runnable_with_memory = add_memory(classify_message_chain, session_id=\"output_only\", context=\"사용자 입력 유형\", save_mode=\"output\")\n",
    "print(runnable_with_memory.invoke({\"input\": \"주문 변경할게요\"}, config={\"configurable\": {\"session_id\": \"output_only\"}}))\n",
    "print(store[\"output_only\"].messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='요청' response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 197, 'total_tokens': 200}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-23573e98-adf9-48dd-8fdb-3ad8a46aa0be-0'\n",
      "[AIMessage(content='사용자 입력 유형\\n요청'), AIMessage(content='사용자 입력 유형\\n요청')]\n"
     ]
    }
   ],
   "source": [
    "runnable_with_memory = add_memory(classify_message_chain, session_id=\"output_only\", context=\"사용자 입력 유형\", save_mode=\"output\")\n",
    "print(runnable_with_memory.invoke({\"input\": \"주문 취소\"}, config={\"configurable\": {\"session_id\": \"output_only\"}}))\n",
    "print(store[\"output_only\"].messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configurable로 session_id 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='문의' response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 211, 'total_tokens': 213}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-1ba7337e-16c4-46ac-acd0-bb0d42e5c692-0'\n",
      "[HumanMessage(content='주문 취소할게'), AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 183, 'total_tokens': 186}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-64719567-142e-4ee1-adee-6963babb05ca-0'), HumanMessage(content='주문 변경도 가능해?'), AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 201, 'total_tokens': 204}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5b6e5bbe-6a7a-4084-a8ae-02ebd756366f-0'), HumanMessage(content='주문 변경할게요'), AIMessage(content='요청', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 218, 'total_tokens': 221}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0b8b5c86-14ef-41a4-a9f3-bebed900959a-0')]\n"
     ]
    }
   ],
   "source": [
    "runnable_with_memory = add_memory(classify_message_chain, session_id=\"output_only\", context=\"사용자 입력 유형\", save_mode=\"output\")\n",
    "print(runnable_with_memory.invoke({\"input\": \"판매 상품 알려줘\"}, config={\"configurable\": {\"session_id\": \"test1\"}}))\n",
    "print(store[\"test1\"].messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
